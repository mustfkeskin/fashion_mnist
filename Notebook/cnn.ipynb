{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# İçerik\n",
    "\n",
    "# 1.Fashion Mnist\n",
    "1. [Load Library](#ch0)\n",
    "1. [Read Data](#ch1)\n",
    "1. [Train Test Validation Split](#ch2)\n",
    "1. [Normalization](#ch3)\n",
    "1. [Convert Inputs for NNs](#ch4)\n",
    "\n",
    "\n",
    "\n",
    "# 2.Models\n",
    "1. [Pipeline](#ch6)\n",
    "2. [deneme](#ch6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch0\"></a>\n",
    "# Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from utils import util, cv_models\n",
    "from utils.random_eraser import get_random_eraser\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import transform\n",
    "\n",
    "#import keras.backend as K\n",
    "#K.set_floatx('float16')\n",
    "#K.set_epsilon(1e-4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch1\"></a>\n",
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../Data/fashion-mnist_train.csv')\n",
    "data_test  = pd.read_csv('../Data/fashion-mnist_test.csv')\n",
    "\n",
    "target_names = {0:\"T-shirt/top\",\n",
    "                1:\"Trouser\",\n",
    "                2:\"Pullover\",\n",
    "                3:\"Dress\",\n",
    "                4:\"Coat\",\n",
    "                5:\"Sandal\",\n",
    "                6:\"Shirt\",\n",
    "                7:\"Sneaker\",\n",
    "                8:\"Bag\",\n",
    "                9:\"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch2\"></a>\n",
    "# Train Test Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data_train.iloc[:, 1:])\n",
    "y = to_categorical(np.array(data_train.iloc[:, 0]))\n",
    "\n",
    "#Here we split validation data to optimiza classifier during training\n",
    "#set random_state for reproduceable result\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "\n",
    "#Test data\n",
    "X_test = np.array(data_test.iloc[:, 1:])\n",
    "y_test = to_categorical(np.array(data_test.iloc[:, 0]))\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test  = X_test.astype('float32')\n",
    "X_val   = X_val.astype('float32')\n",
    "\n",
    "\n",
    "#get the indices to be plotted\n",
    "y_test_true  = data_test.iloc[:, 0]\n",
    "y_train_true = np.argmax(y_train, axis=1, out=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch3\"></a>\n",
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test  /= 255\n",
    "X_val   /= 255\n",
    "\n",
    "num_classes = len(np.unique(data_train.iloc[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch4\"></a>\n",
    "# Convert Inputs For NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_32x32(imgs):\n",
    "    imgs = imgs.reshape((-1, 28, 28, 1))\n",
    "    resized_imgs = np.zeros((imgs.shape[0], 32, 32, 1))\n",
    "    for i in range(imgs.shape[0]):\n",
    "        resized_imgs[i, ..., 0] = transform.resize(imgs[i, ..., 0], (32, 32))\n",
    "    return resized_imgs\n",
    "\n",
    "# Flat Input\n",
    "X_train_flat = X_train\n",
    "X_test_flat  = X_test\n",
    "X_val_flat   = X_val\n",
    "\n",
    "# 28x28 Images for simple CNN\n",
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train28 = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test28  = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val28   = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# 32x32 Images for Deeper Architecture\n",
    "X_train32 = resize_32x32(X_train)\n",
    "X_val32   = resize_32x32(X_val)\n",
    "X_test32  = resize_32x32(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch6\"></a>\n",
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [#'mlp.h5',            \\\n",
    "         #'simpleCNN.h5',      \\\n",
    "         #'CNNDropout.h5',     \\\n",
    "         #'CNNBatchNorm.h5',   \\\n",
    "         #'simpleVGG.h5',      \\\n",
    "         #'simpleInception.h5', \\\n",
    "         #'simpleResnet.h5',   \\\n",
    "         'wideResnet.h5',     \\\n",
    "         'mobileNetV2.h5',    \\\n",
    "         #'Resnet50.h5',    \\\n",
    "         #'NASNet.h5'\n",
    "        ]\n",
    "\n",
    "flat  = ['mlp.h5']\n",
    "\n",
    "inp28 = ['simpleCNN.h5',   \\\n",
    "         'CNNDropout.h5',  \\\n",
    "         'CNNBatchNorm.h5']\n",
    "\n",
    "inp32 = ['Resnet50.h5', \\\n",
    "         'mobileNetV2.h5', \\\n",
    "         'wideResnet.h5', \\\n",
    "         'NASNet.h5', \\\n",
    "         'simpleVGG.h5',      \\\n",
    "         'simpleInception.h5',\\\n",
    "         'simpleResnet.h5' ]\n",
    "\n",
    "\n",
    "\n",
    "models = [#cv_models.buildMLP(),\n",
    "          #cv_models.buildSimpleCNN(),\n",
    "          #cv_models.buildCNNDropout(),\n",
    "          #cv_models.buildCNNBatchNorm(),\n",
    "          #cv_models.buildSimpleVGG(),\n",
    "          #cv_models.buildSimpleInception(),\n",
    "          #cv_models.buildSimpleResnet(),\n",
    "          cv_models.build_wide_resnet(16, 4),\n",
    "          cv_models.buildMobileNetV2(),\n",
    "          #cv_models.buildResNet50(),\n",
    "          #cv_models.buildNASNet()\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_pred_df  = pd.DataFrame()\n",
    "train_pred_df = pd.DataFrame()\n",
    "metrics_dict  = {}\n",
    "history_dict  = {}\n",
    "\n",
    "# train each model\n",
    "for model, model_name in zip(models, names):\n",
    "    if(model_name in flat):\n",
    "        X_train = X_train_flat\n",
    "        X_test  = X_test_flat\n",
    "        X_val   = X_val_flat\n",
    "    elif(model_name in inp28):\n",
    "        X_train = X_train28\n",
    "        X_test  = X_test28\n",
    "        X_val   = X_val28\n",
    "    elif(model_name in inp32):\n",
    "        X_train = X_train32\n",
    "        X_test  = X_test32\n",
    "        X_val   = X_val32\n",
    "      \n",
    "    print(\"----------------------------\")\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history  = model.fit(X_train, y_train,\n",
    "                     batch_size=64, epochs=20,\n",
    "                     verbose=2,\n",
    "                     validation_data=(X_val, y_val))\n",
    "    \n",
    "    # evulation\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    y_pred_test, metrics = util.get_pred_and_metrics(model,\n",
    "                                                X_test,\n",
    "                                                y_test_true,\n",
    "                                                target_names)\n",
    "    \n",
    "    y_pred_train, metrics = util.get_pred_and_metrics(model,\n",
    "                                                X_train,\n",
    "                                                y_train_true,\n",
    "                                                target_names)\n",
    "\n",
    "    train_pred_df[model_name] = y_pred_train\n",
    "    test_pred_df[model_name]  = y_pred_test\n",
    "    metrics_dict[model_name]  = metrics\n",
    "    history_dict[model_name]  = history\n",
    "    \n",
    "    print(model_name)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    # save model, plot mdeol acc,loss and confussion matrix\n",
    "    util.save_model(model, model_name)\n",
    "    model_name = model_name.split(\".\")[0]\n",
    "    util.plot_accuracy_and_loss(history, model_name)\n",
    "    util.plot_confussion_matrix(y_test_true, y_pred_test, target_names, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('history8_9.pickle', 'wb') as f:\n",
    "    pickle.dump(history_dict, f)\n",
    "    \n",
    "    \n",
    "with open('metrics8_9.pickle', 'wb') as f:\n",
    "    pickle.dump(metrics_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = test_pred_df\n",
    "y_true  = y_test_true\n",
    "\n",
    "y_pred = np.asarray([np.argmax(np.bincount(pred_df.loc[row,:])) for row in range(pred_df.shape[0])])\n",
    "\n",
    "prfs = util.precision_recall_fscore_support(y_true, y_pred)\n",
    "df   = util.accuracyMetrics2df(prfs, target_names = target_names.values())\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(acc)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=  ['accuracy'])\n",
    "\n",
    "\n",
    "X_train = np.array(train_pred_df)\n",
    "X_test  = np.array(test_pred_df)\n",
    "\n",
    "history  = model.fit(X_train, y_train,\n",
    "                     batch_size=64, epochs=10,\n",
    "                     verbose=0)\n",
    "    \n",
    "# evulation\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "y_pred, metrics = util.get_pred_and_metrics(model,\n",
    "                                            X_test,\n",
    "                                            y_test_true,\n",
    "                                            target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation and CallBacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  \n",
    "            samplewise_center=False, \n",
    "            featurewise_std_normalization=False,  \n",
    "            samplewise_std_normalization=False,\n",
    "            zca_whitening=False, \n",
    "            rotation_range=0,  \n",
    "            zoom_range = 0.02,  \n",
    "            width_shift_range=0.05,  \n",
    "            height_shift_range=0.05,  \n",
    "            horizontal_flip=False,  \n",
    "            vertical_flip=False,\n",
    "            preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=False)) \n",
    "\n",
    "\n",
    "# CallBacks\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=10, \n",
    "                                            verbose=0, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df  = pd.DataFrame()\n",
    "train_pred_df = pd.DataFrame()\n",
    "metrics_dict  = {}\n",
    "history_dict  = {}\n",
    "\n",
    "# train each model\n",
    "for model, model_name in zip(models, names):\n",
    "    if(model_name in flat):\n",
    "        continue\n",
    "        X_train = X_train_flat\n",
    "        X_test  = X_test_flat\n",
    "        X_val   = X_val_flat\n",
    "    elif(model_name in inp28):\n",
    "        X_train = X_train28\n",
    "        X_test  = X_test28\n",
    "        X_val   = X_val28\n",
    "    elif(model_name in inp32):\n",
    "        X_train = X_train32\n",
    "        X_test  = X_test32\n",
    "        X_val   = X_val32\n",
    "        \n",
    "    datagen.fit(X_train)\n",
    "\n",
    "      \n",
    "    print(\"----------------------------\")\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history  = model.fit_generator(datagen.flow(X_train, y_train,\n",
    "                     batch_size=64), steps_per_epoch=len(X_train) / 64,\n",
    "                     epochs = 10,\n",
    "                     verbose=0,\n",
    "                     validation_data=(X_val, y_val),\n",
    "                     callbacks=[early, learning_rate_reduction])\n",
    "    \n",
    "    # evulation\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    y_pred_test, metrics = util.get_pred_and_metrics(model,\n",
    "                                                X_test,\n",
    "                                                y_test_true,\n",
    "                                                target_names)\n",
    "    \n",
    "    y_pred_train, metrics = util.get_pred_and_metrics(model,\n",
    "                                                X_train,\n",
    "                                                y_train_true,\n",
    "                                                target_names)\n",
    "\n",
    "    train_pred_df[model_name] = y_pred_train\n",
    "    test_pred_df[model_name]  = y_pred_test\n",
    "    metrics_dict[model_name]  = metrics\n",
    "    history_dict[model_name]  = history\n",
    "    \n",
    "    print(model_name)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    #print(metrics_df)\n",
    "    \n",
    "    # save model, plot mdeol acc,loss and confussion matrix\n",
    "    util.save_model(model, model_name)\n",
    "    #util.plot_accuracy_and_loss(history)\n",
    "    #util.plot_confussion_matrix(y_true, y_pred, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = list(y_pred)\n",
    "\n",
    "correct = np.nonzero(y_pred==y_true)[0]\n",
    "incorrect = np.nonzero(y_pred!=y_true)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Correctly Classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, correct in enumerate(correct[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[correct].reshape(32,32), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(y_pred[correct], y_true[correct]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Incorrectly Classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, incorrect in enumerate(incorrect[0:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[incorrect].reshape(32,32), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(y_pred[incorrect], y_true[incorrect]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
